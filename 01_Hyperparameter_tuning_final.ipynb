{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "vocal-mentor",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning using HyperDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caring-touch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.6.13 |Anaconda, Inc.| (default, Feb 23 2021, 12:58:59) \n",
      "[GCC Clang 10.0.0 ]\n",
      "SDK version: 1.23.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import azureml\n",
    "import logging\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "import joblib\n",
    "\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core import Environment\n",
    "\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.core import ScriptRunConfig\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "from azureml.pipeline.steps import AutoMLStep\n",
    "\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling, BayesianParameterSampling\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.parameter_expressions import uniform, quniform, choice\n",
    "\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.runconfig import EnvironmentDefinition\n",
    "from azureml.core.runconfig import CondaDependencies\n",
    "from azureml.core.model import InferenceConfig, Model\n",
    "\n",
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "from azureml.core.model import Model, InferenceConfig\n",
    "\n",
    "from azureml.train.automl import constants\n",
    "\n",
    "from train import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Check system and core SDK version number\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "continent-creek",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mThe default web browser has been opened at https://login.microsoftonline.com/common/oauth2/authorize. Please continue the login in the web browser. If no web browser is available or if the web browser fails to open, use device code flow with `az login --use-device-code`.\u001b[0m\n",
      "\u001b[33mYou have logged in. Now let us find all the subscriptions to which you have access...\u001b[0m\n",
      "[\n",
      "  {\n",
      "    \"cloudName\": \"AzureCloud\",\n",
      "    \"homeTenantId\": \"660b3398-b80e-49d2-bc5b-ac1dc93b5254\",\n",
      "    \"id\": \"2c48c51c-bd47-40d4-abbe-fb8eabd19c8c\",\n",
      "    \"isDefault\": true,\n",
      "    \"managedByTenants\": [],\n",
      "    \"name\": \"Udacity CloudLabs Sub - 03\",\n",
      "    \"state\": \"Enabled\",\n",
      "    \"tenantId\": \"660b3398-b80e-49d2-bc5b-ac1dc93b5254\",\n",
      "    \"user\": {\n",
      "      \"name\": \"odl_user_142985@udacitylabs.onmicrosoft.com\",\n",
      "      \"type\": \"user\"\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "!az login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "breeding-packing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>online_news_project</td><td>quick-starts-ws-142985</td><td><a href=\"https://ml.azure.com/experiments/online_news_project?wsid=/subscriptions/2c48c51c-bd47-40d4-abbe-fb8eabd19c8c/resourcegroups/aml-quickstarts-142985/workspaces/quick-starts-ws-142985\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Experiment(Name: online_news_project,\n",
       "Workspace: quick-starts-ws-142985)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactive_auth = InteractiveLoginAuthentication(tenant_id=\"660b3398-b80e-49d2-bc5b-ac1dc93b5254\")\n",
    "ws = Workspace.get(subscription_id=\"2c48c51c-bd47-40d4-abbe-fb8eabd19c8c\",\n",
    "                   resource_group=\"aml-quickstarts-142985\",\n",
    "                   name=\"quick-starts-ws-142985\",\n",
    "                   auth=interactive_auth)\n",
    "\n",
    "experiment_name = 'online_news_project'\n",
    "experiment=Experiment(ws, experiment_name)\n",
    "experiment\n",
    "# ws = Workspace.from_config()\n",
    "# print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "proud-occasions",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Workspace name</th>\n",
       "      <td>quick-starts-ws-142985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Azure region</th>\n",
       "      <td>southcentralus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subscription id</th>\n",
       "      <td>2c48c51c-bd47-40d4-abbe-fb8eabd19c8c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resource group</th>\n",
       "      <td>aml-quickstarts-142985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment Name</th>\n",
       "      <td>online_news_project</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     \n",
       "Workspace name                 quick-starts-ws-142985\n",
       "Azure region                           southcentralus\n",
       "Subscription id  2c48c51c-bd47-40d4-abbe-fb8eabd19c8c\n",
       "Resource group                 aml-quickstarts-142985\n",
       "Experiment Name                   online_news_project"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_data = {'Workspace name': ws.name,\n",
    "            'Azure region': ws.location,\n",
    "            'Subscription id': ws.subscription_id,\n",
    "            'Resource group': ws.resource_group,\n",
    "            'Experiment Name': experiment.name}\n",
    "\n",
    "az_data = pd.DataFrame.from_dict(data = dic_data, orient='index')\n",
    "az_data.rename(columns={0:''}, inplace = True)\n",
    "az_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sound-vegetation",
   "metadata": {},
   "source": [
    "## Create or Attach an AmlCompute cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "charming-sender",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cpu-cluster. Use it.\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n",
      "{'currentNodeCount': 1, 'targetNodeCount': 1, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 1, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2021-04-18T01:00:23.900000+00:00', 'errors': None, 'creationTime': '2021-04-18T00:58:49.540122+00:00', 'modifiedTime': '2021-04-18T00:59:05.307569+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 1, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_DS12_V2'}\n"
     ]
    }
   ],
   "source": [
    "# Define CPU cluster name\n",
    "compute_target_name = \"cpu-cluster\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=compute_target_name)\n",
    "    print(\"Found existing cpu-cluster. Use it.\")\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_DS12_V2\",\n",
    "                                                           min_nodes=1, \n",
    "                                                           max_nodes=4) \n",
    "    compute_target = ComputeTarget.create(ws, compute_target_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output=True)\n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-estonia",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset used in this project is a dataset made available on UCI Machine Learning Repository called [Online News Popularity Data Set](https://archive.ics.uci.edu/ml/datasets/Online+News+Popularity#).\n",
    "\n",
    "The dataset summarizes heterogeneous set of features about the articles published by Mashable between 2013 and 2015.\n",
    "\n",
    "- Number of Instances: 39797\n",
    "- Number of Attributes: 61 \n",
    "    - 58 predictive attributes \n",
    "    - 2 non-predictive (`url` and `timedelta`) \n",
    "    - 1 target column\n",
    "    \n",
    "We will also apply the `Boruta` step for feature selection before exporting the data to our defined Datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "compliant-barcelona",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31715 x 47 table of data:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 31715 entries, 38512 to 35050\n",
      "Data columns (total 47 columns):\n",
      "n_tokens_title                   31715 non-null float64\n",
      "n_tokens_content                 31715 non-null float64\n",
      "n_unique_tokens                  31715 non-null float64\n",
      "num_hrefs                        31715 non-null float64\n",
      "num_self_hrefs                   31715 non-null float64\n",
      "num_imgs                         31715 non-null float64\n",
      "num_videos                       31715 non-null float64\n",
      "average_token_length             31715 non-null float64\n",
      "num_keywords                     31715 non-null float64\n",
      "data_channel_is_entertainment    31715 non-null int64\n",
      "data_channel_is_bus              31715 non-null int64\n",
      "data_channel_is_socmed           31715 non-null int64\n",
      "data_channel_is_tech             31715 non-null int64\n",
      "data_channel_is_world            31715 non-null int64\n",
      "kw_min_min                       31715 non-null float64\n",
      "kw_max_min                       31715 non-null float64\n",
      "kw_min_max                       31715 non-null float64\n",
      "kw_avg_max                       31715 non-null float64\n",
      "kw_min_avg                       31715 non-null float64\n",
      "kw_max_avg                       31715 non-null float64\n",
      "kw_avg_avg                       31715 non-null float64\n",
      "self_reference_min_shares        31715 non-null float64\n",
      "self_reference_max_shares        31715 non-null float64\n",
      "weekday_is_wednesday             31715 non-null int64\n",
      "weekday_is_saturday              31715 non-null int64\n",
      "weekday_is_sunday                31715 non-null int64\n",
      "is_weekend                       31715 non-null int64\n",
      "LDA_00                           31715 non-null float64\n",
      "LDA_01                           31715 non-null float64\n",
      "LDA_02                           31715 non-null float64\n",
      "LDA_03                           31715 non-null float64\n",
      "LDA_04                           31715 non-null float64\n",
      "global_subjectivity              31715 non-null float64\n",
      "global_sentiment_polarity        31715 non-null float64\n",
      "global_rate_positive_words       31715 non-null float64\n",
      "global_rate_negative_words       31715 non-null float64\n",
      "rate_positive_words              31715 non-null float64\n",
      "rate_negative_words              31715 non-null float64\n",
      "avg_positive_polarity            31715 non-null float64\n",
      "min_positive_polarity            31715 non-null float64\n",
      "max_positive_polarity            31715 non-null float64\n",
      "avg_negative_polarity            31715 non-null float64\n",
      "min_negative_polarity            31715 non-null float64\n",
      "max_negative_polarity            31715 non-null float64\n",
      "title_subjectivity               31715 non-null float64\n",
      "title_sentiment_polarity         31715 non-null float64\n",
      "abs_title_sentiment_polarity     31715 non-null float64\n",
      "dtypes: float64(38), int64(9)\n",
      "memory usage: 11.6 MB\n"
     ]
    }
   ],
   "source": [
    "DATA_LOC = \"https://raw.githubusercontent.com/franckess/AzureML_Capstone/main/data/OnlineNewsPopularity.csv\"\n",
    "BORUTA_LOC = \"https://github.com/franckess/AzureML_Capstone/releases/download/1.1/boruta_model_final.pkl\"\n",
    "\n",
    "# Loading data\n",
    "df = pd.read_csv(DATA_LOC)\n",
    "\n",
    "# Removing space character in the feature names\n",
    "df.columns=df.columns.str.replace(' ','')\n",
    "\n",
    "# Drop URL column\n",
    "df = df.drop(['url'], axis=1)\n",
    "\n",
    "# Perform Data pre-processing\n",
    "df = corr_drop_cols(df)\n",
    "df = create_label(df)\n",
    "df = scaling_num(df)\n",
    "df = feature_selection(df, BORUTA_LOC)\n",
    "    \n",
    "# Split train data into train & test\n",
    "X_train, X_test, y_train, y_test = split_train_test(df)\n",
    "\n",
    "m, k = X_train.shape\n",
    "print(\"{} x {} table of data:\".format(m, k))\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-reality",
   "metadata": {},
   "source": [
    "## Upload data to Azure Datatore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "proper-graphics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading ./data/OnlineNewsPopularity.csv\n",
      "Uploaded ./data/OnlineNewsPopularity.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_55737bc15eb54d20a6a645a5ffec8218"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datastore = ws.get_default_datastore()\n",
    "datastore.upload_files(files = ['./data/OnlineNewsPopularity.csv'], \n",
    "                       target_path='data/', \n",
    "                       overwrite=True, \n",
    "                       show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "angry-configuration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datastore type: AzureBlob\n",
      "Account name: mlstrg142985\n",
      "Container name: azureml-blobstore-4d8774c1-27e9-47c1-b92b-547a17c80a82\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Datastore type: \" + datastore.datastore_type,\n",
    "    \"Account name: \" + datastore.account_name,\n",
    "    \"Container name: \" + datastore.container_name,\n",
    "    sep=\"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "convenient-johnson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$AZUREML_DATAREFERENCE_f88cf551a9d7444580c30286a23fa4d2\n"
     ]
    }
   ],
   "source": [
    "# Get data reference object for the data path\n",
    "ds_data = datastore.path('data/')\n",
    "print(ds_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-ireland",
   "metadata": {},
   "source": [
    "## HyperDrive Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-james",
   "metadata": {},
   "source": [
    "### Create an environment\n",
    "\n",
    "Define a conda environment YAML file with your training script dependencies and create an Azure ML environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile hyperdrive_dependencies.yml\n",
    "\n",
    "name: project_environment\n",
    "dependencies:\n",
    "- python=3.6.2\n",
    "- pip:\n",
    "  - azureml-train-automl-runtime==1.24.0\n",
    "  - Werkzeug==0.16.1\n",
    "  - inference-schema\n",
    "  - azureml-interpret==1.24.0\n",
    "  - azureml-defaults==1.24.0\n",
    "  - pingouin\n",
    "  - lightgbm\n",
    "  - joblib  \n",
    "  - Boruta\n",
    "- numpy>=1.16.0,<1.19.0\n",
    "- pandas==0.25.1\n",
    "- scikit-learn==0.22.1\n",
    "- py-xgboost<=0.90\n",
    "- fbprophet==0.5\n",
    "- holidays==0.9.11\n",
    "- psutil>=5.2.2,<6.0.0\n",
    "channels:\n",
    "- anaconda\n",
    "- conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "mexican-growing",
   "metadata": {},
   "outputs": [],
   "source": [
    "udacity_env = Environment.from_conda_specification(name = 'udacity-env', file_path = './hyperdrive_dependencies.yml')\n",
    "udacity_env.register(ws)\n",
    "\n",
    "# Specify an Ubuntu base image\n",
    "udacity_env.docker.enabled = True\n",
    "udacity_env.python.user_managed_dependencies = False\n",
    "udacity_env.docker.base_image = 'mcr.microsoft.com/azureml/base:openmpi3.1.2-ubuntu18.04'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biblical-reynolds",
   "metadata": {},
   "source": [
    "Build the image just to confirm it works appropriately or identify any errors prior to deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-eligibility",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# build = udacity_env.build(workspace=ws)\n",
    "# build.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "liked-secretary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROM mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210129.v1@sha256:19fe6a6202757242643beace8d3d690519f431deb21adc072989185425a22133\n",
      "USER root\n",
      "RUN mkdir -p $HOME/.cache\n",
      "WORKDIR /\n",
      "COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      "RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      "COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      "RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_d32c6a42b04d5ead1baaef3bc63324e7 -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      "# AzureML Conda environment name: azureml_d32c6a42b04d5ead1baaef3bc63324e7\n",
      "ENV PATH /azureml-envs/azureml_d32c6a42b04d5ead1baaef3bc63324e7/bin:$PATH\n",
      "COPY azureml-environment-setup/send_conda_dependencies.py azureml-environment-setup/send_conda_dependencies.py\n",
      "COPY azureml-environment-setup/environment_context.json azureml-environment-setup/environment_context.json\n",
      "RUN python /azureml-environment-setup/send_conda_dependencies.py -p /azureml-envs/azureml_d32c6a42b04d5ead1baaef3bc63324e7\n",
      "ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_d32c6a42b04d5ead1baaef3bc63324e7\n",
      "ENV LD_LIBRARY_PATH /azureml-envs/azureml_d32c6a42b04d5ead1baaef3bc63324e7/lib:$LD_LIBRARY_PATH\n",
      "COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
      "RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n",
      "ENV AZUREML_ENVIRONMENT_IMAGE True\n",
      "CMD [\"bash\"]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "details = udacity_env.get_image_details(ws)\n",
    "print(details.dockerfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-numbers",
   "metadata": {},
   "source": [
    "### Tune hyperparameters using `HyperDrive`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weekly-contact",
   "metadata": {},
   "source": [
    "In the following block, I tune my set of hyperparameters for the `LightGBM` model. The ranges of parameters for the `LightGBM` used were chosen considering the parameters tuning guides for different scenarios provided here.\n",
    "\n",
    "The code below does a parallel search of the hyperparameter space using a Bayesian sampling method which does not support termination policy. Therefore, `policy=None`.\n",
    "\n",
    "> __Note that when using Bayesian sampling, the number of concurrent runs has an impact on the effectiveness of the tuning process. Typically, a smaller number of concurrent runs leads to better sampling convergence. That is because some runs start without fully benefiting from runs that are still running.__\n",
    "\n",
    "In order to compare the performance of HyperDrive with the one of AutoML we chose as objective metric of `LightGBM` __Accuracy__ score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "formed-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SKLearn estimator for use with train.py\n",
    "src = ScriptRunConfig(source_directory='.',\n",
    "                      script='train.py',\n",
    "                      compute_target=compute_target,\n",
    "                      environment=udacity_env)\n",
    "\n",
    "# Specify hyperparameter space\n",
    "param_sampling = BayesianParameterSampling(\n",
    "    {\n",
    "        \"--num-leaves\": quniform(8, 128, 1),\n",
    "        \"--min-data-in-leaf\": quniform(20, 500, 10),\n",
    "        \"--learning-rate\": choice(\n",
    "            1e-4, 1e-3, 5e-3, 1e-2, 1.5e-2, 2e-2, 3e-2, 5e-2, 1e-1\n",
    "        ),\n",
    "        \"--feature-fraction\": uniform(0.1, 1),\n",
    "        \"--bagging-fraction\": uniform(0.1, 1),\n",
    "        \"--bagging-freq\": quniform(1, 30, 1),\n",
    "        \"--max-depth\": quniform(5, 50, 5)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create a HyperDriveConfig using the estimator, hyperparameter sampler, and policy.\n",
    "hyperdrive_config = HyperDriveConfig(run_config=src,\n",
    "                                     hyperparameter_sampling=param_sampling,\n",
    "                                     policy=None ,\n",
    "                                     primary_metric_name=\"Accuracy\",\n",
    "                                     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "                                     max_total_runs=50,\n",
    "                                     max_concurrent_runs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "likely-coupon",
   "metadata": {},
   "outputs": [
    {
     "ename": "AzureMLException",
     "evalue": "AzureMLException:\n\tMessage: Failed to flush task queue within 300 seconds\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Failed to flush task queue within 300 seconds\",\n        \"inner_error\": {\n            \"code\": \"ResourceExhausted\",\n            \"inner_error\": {\n                \"code\": \"Timeout\"\n            }\n        }\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAzureMLException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-1ba29a3c969a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Submit hyperdrive run to the experiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhyperdrive_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperdrive_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/udacity/lib/python3.6/site-packages/azureml/_jupyter_common/__init__.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, config, tags, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_experiment_submit_notebook_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_submit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_submit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0m_update_run_created_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/udacity/lib/python3.6/site-packages/azureml/core/experiment.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, config, tags, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0msubmit_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_experiment_submit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"submit config {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubmit_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtags\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/udacity/lib/python3.6/site-packages/azureml/train/hyperdrive/_search.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(hyperdrive_config, workspace, experiment_name, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         experiment_dto = _create_experiment_dto(hyperdrive_config, workspace, experiment_name,\n\u001b[0;32m--> 141\u001b[0;31m                                                 telemetry_values, activity_logger, **kwargs)\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/udacity/lib/python3.6/site-packages/azureml/train/hyperdrive/_search.py\u001b[0m in \u001b[0;36m_create_experiment_dto\u001b[0;34m(hyperdrive_config, workspace, experiment_name, telemetry_values, activity_logger, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhyperdrive_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_directory\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0msnapshot_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSnapshotsClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0msnapshot_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msnapshot_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_snapshot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperdrive_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mactivity_logger\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/udacity/lib/python3.6/site-packages/azureml/_restclient/snapshots_client.py\u001b[0m in \u001b[0;36mcreate_snapshot\u001b[0;34m(self, file_or_folder_path, retry_on_failure, raise_on_validation_failure)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcreate_session_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mrevision_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_upload_snapshot_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentries_to_send\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_or_folder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mcreate_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"ParentSnapshotId\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparent_snapshot_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Tags\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Properties\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msnapshot_properties\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/udacity/lib/python3.6/site-packages/azureml/_restclient/snapshots_client.py\u001b[0m in \u001b[0;36m_upload_snapshot_files\u001b[0;34m(self, entries_to_send, file_or_folder_path, exclude_function)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0mfile_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblob_uri_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fileNodes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m             \u001b[0mrevision_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_upload_files_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_or_folder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrevision_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/udacity/lib/python3.6/site-packages/azureml/_restclient/snapshots_client.py\u001b[0m in \u001b[0;36m_upload_files_batch\u001b[0;34m(self, file_nodes, file_or_folder_path, session)\u001b[0m\n\u001b[1;32m    223\u001b[0m                     \u001b[0mfile_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_or_folder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                     \u001b[0mfile_revision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"FullName\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"BlobUri\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mupload_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"FileSize\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfile_size\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                     \u001b[0mrevision_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_revision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrevision_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/udacity/lib/python3.6/site-packages/azureml/_common/async_utils/task_queue.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[Stop] - waiting default timeout\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# TODO: Adding functions with this method needs to be more configurable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/udacity/lib/python3.6/site-packages/azureml/_common/async_utils/task_queue.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self, source, timeout_seconds)\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mFlushTaskTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_seconds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_seconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                 )\n\u001b[0;32m--> 135\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAzureMLException\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mazureml_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAzureMLException\u001b[0m: AzureMLException:\n\tMessage: Failed to flush task queue within 300 seconds\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Failed to flush task queue within 300 seconds\",\n        \"inner_error\": {\n            \"code\": \"ResourceExhausted\",\n            \"inner_error\": {\n                \"code\": \"Timeout\"\n            }\n        }\n    }\n}"
     ]
    }
   ],
   "source": [
    "# Submit hyperdrive run to the experiment \n",
    "hyperdrive_run = experiment.submit(config=hyperdrive_config, show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-waters",
   "metadata": {},
   "source": [
    "## Run Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-revolution",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show run details with the Jupyter widget\n",
    "RunDetails(hyperdrive_run).show()\n",
    "hyperdrive_run.wait_for_completion(show_output=True)\n",
    "hyperdrive_run.get_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-conditioning",
   "metadata": {},
   "source": [
    "## Retrieve and Save Best Model\n",
    "\n",
    "Here I retrieve and save the best model as well as display all the properties of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-lying",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = hyperdrive_run.get_best_run_by_primary_metric() \n",
    "get_best_metrics = best_run.get_metrics()\n",
    "parameter_values = best_run.get_details()[\"runDefinition\"][\"arguments\"]\n",
    "\n",
    "print('Best Run ID: ', best_run.id, sep='\\n')\n",
    "print('\\n Metrics: ', get_best_metrics)\n",
    "print('\\n Best Run Accuracy:', get_best_metrics['Accuracy'])\n",
    "print('\\n Best model hyperparameter values', parameter_values, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-falls",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run.get_file_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-flashing",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run.download_file(\"outputs/lgb_model.pkl\",\"output/hyperdrive_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-policy",
   "metadata": {},
   "source": [
    "## Model Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-julian",
   "metadata": {},
   "source": [
    "### Register our best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-things",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_run.register_model(model_name = 'best_model', model_path = './outputs/lgb_model.pkl')\n",
    "print(\"Model successfully registered.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-customer",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Name:', model.name)\n",
    "print('Version:', model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-ground",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.get_model_path(model_name = 'best_model', _workspace=ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-blame",
   "metadata": {},
   "source": [
    "### Prepare the `score.py` script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-serbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('score.py') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-gibson",
   "metadata": {},
   "source": [
    "### Inference configuration\n",
    "\n",
    "Create an inference config and deploy the model as a web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-caution",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_file_name = './score.py'\n",
    "inference_config = InferenceConfig(entry_script=script_file_name)\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 2, \n",
    "                                               memory_gb = 4, \n",
    "                                               tags = {'Company': \"Mashable\", 'Type': \"Hyperdrive\", \"Version\":\"1\"}, \n",
    "                                               description = 'sample service for Capstone Project Hyperdrive Classifier for Online News popularity')\n",
    "aci_service_name = 'hyperdrive-final-deployment'\n",
    "print(aci_service_name)\n",
    "aci_service = Model.deploy(ws, aci_service_name, [model], inference_config, aciconfig)\n",
    "aci_service.wait_for_deployment(True)\n",
    "print(f'\\nservice state: {aci_service.state}\\n')\n",
    "print(f'scoring URI: \\n{aci_service.scoring_uri}\\n')\n",
    "print(f'swagger URI: \\n{aci_service.swagger_uri}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-solomon",
   "metadata": {},
   "source": [
    "### Testing our web service\n",
    "\n",
    "Let's send a request to the web service we deployed to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-hudson",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.concat([X_test, y_test], axis=1)\n",
    "test_data = test_data[10:15]\n",
    "display(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-employee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove label column\n",
    "label = test_data.pop('label')\n",
    "\n",
    "# convert test input data to dictionary form\n",
    "input_data = json.dumps({'data': test_data.to_dict(orient='records')})\n",
    "\n",
    "# print test input data\n",
    "print(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-california",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the content type\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "# Make the request and display the response\n",
    "resp = requests.post(aci_service.scoring_uri, input_data, headers=headers)\n",
    "\n",
    "print(\"Response Code : \", resp.status_code)\n",
    "print(\"Predicted Value : \",resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formed-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = aci_service.run(test_data)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UdacityEnv",
   "language": "python",
   "name": "udacityenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
